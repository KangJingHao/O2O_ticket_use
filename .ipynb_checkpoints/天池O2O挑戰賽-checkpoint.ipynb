{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***off_train資料內容***\n",
    "\n",
    "**User_id  用户ID**\n",
    "\n",
    "**Merchant_id  商户ID**\n",
    "\n",
    "**Coupon_id  优惠券ID：null表示无优惠券消费，此时Discount_rate和Date_received字段无意义**\n",
    "\n",
    "**Discount_rate  优惠率：x \\in [0,1]代表折扣率；x:y表示满x减y。单位是元**\n",
    "\n",
    "**Distance user经常活动的地点离该merchant的最近门店距离是x*500米（如果是连锁店，则取最近的一家门店），x\\in[0,10]；null表示无此信息，0表示低于500米，10表示大于5公里；**\n",
    "\n",
    "**Date_received  领取优惠券日期**\n",
    "\n",
    "**Date  消费日期：如果Date=null & Coupon_id != null，该记录表示领取优惠券但没有使用，即负样本；如果Date!=null & Coupon_id = null，则表示普通消费日期；如果Date!=null & Coupon_id != null，则表示用优惠券消费日期，即正样本；**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_train = pd.read_csv('ccf_online_stage1_train.csv',header=0,keep_default_na=False)\n",
    "online_train.columns=['user_id','merchant_id','action','coupon_id','discount_rate','date_received','date']\n",
    "off_train = pd.read_csv('ccf_offline_stage1_train.csv',header=0,keep_default_na=False)\n",
    "off_train.columns=['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']\n",
    "off_test = pd.read_csv('ccf_offline_stage1_test_revised.csv',header=0,keep_default_na=False)\n",
    "off_test.columns = ['user_id','merchant_id','coupon_id','discount_rate','distance','date_received']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>action</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>date_received</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13740231</td>\n",
       "      <td>18907</td>\n",
       "      <td>2</td>\n",
       "      <td>100017492</td>\n",
       "      <td>500:50</td>\n",
       "      <td>20160513</td>\n",
       "      <td>null</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13740231</td>\n",
       "      <td>34805</td>\n",
       "      <td>1</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>20160321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14336199</td>\n",
       "      <td>18907</td>\n",
       "      <td>0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>20160618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14336199</td>\n",
       "      <td>18907</td>\n",
       "      <td>0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>20160618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14336199</td>\n",
       "      <td>18907</td>\n",
       "      <td>0</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>null</td>\n",
       "      <td>20160618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id  merchant_id  action  coupon_id discount_rate date_received  \\\n",
       "0  13740231        18907       2  100017492        500:50      20160513   \n",
       "1  13740231        34805       1       null          null          null   \n",
       "2  14336199        18907       0       null          null          null   \n",
       "3  14336199        18907       0       null          null          null   \n",
       "4  14336199        18907       0       null          null          null   \n",
       "\n",
       "       date  \n",
       "0      null  \n",
       "1  20160321  \n",
       "2  20160618  \n",
       "3  20160618  \n",
       "4  20160618  "
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "online_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1754884 entries, 0 to 1754883\n",
      "Data columns (total 7 columns):\n",
      "user_id          int64\n",
      "merchant_id      int64\n",
      "coupon_id        object\n",
      "discount_rate    object\n",
      "distance         object\n",
      "date_received    object\n",
      "date             object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 93.7+ MB\n"
     ]
    }
   ],
   "source": [
    "off_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>coupon_id</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>distance</th>\n",
       "      <th>date_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4129537</td>\n",
       "      <td>450</td>\n",
       "      <td>9983</td>\n",
       "      <td>30:5</td>\n",
       "      <td>1</td>\n",
       "      <td>20160712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6949378</td>\n",
       "      <td>1300</td>\n",
       "      <td>3429</td>\n",
       "      <td>30:5</td>\n",
       "      <td>null</td>\n",
       "      <td>20160706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2166529</td>\n",
       "      <td>7113</td>\n",
       "      <td>6928</td>\n",
       "      <td>200:20</td>\n",
       "      <td>5</td>\n",
       "      <td>20160727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2166529</td>\n",
       "      <td>7113</td>\n",
       "      <td>1808</td>\n",
       "      <td>100:10</td>\n",
       "      <td>5</td>\n",
       "      <td>20160727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6172162</td>\n",
       "      <td>7605</td>\n",
       "      <td>6500</td>\n",
       "      <td>30:1</td>\n",
       "      <td>2</td>\n",
       "      <td>20160708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  merchant_id  coupon_id discount_rate distance  date_received\n",
       "0  4129537          450       9983          30:5        1       20160712\n",
       "1  6949378         1300       3429          30:5     null       20160706\n",
       "2  2166529         7113       6928        200:20        5       20160727\n",
       "3  2166529         7113       1808        100:10        5       20160727\n",
       "4  6172162         7605       6500          30:1        2       20160708"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "off_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用滑窗法將數據進行拆分\n",
    "#將2016/1/1~2016/4/13的數據提取特徵，利用2016/4/14-2016/05/14作為測試集 --> feature1、dataset1\n",
    "#將2016/2/1~2016/5/14的數據提取特徵，利用2016/5/15-2016/06/15作為測試集 --> feature2、dataset2\n",
    "#將2016/3/15~2016/6/30的數據提取特徵，利用2016/7/1-2016/07/31作為測試集 --> feature3、data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用於測試集提取特徵的數據區間\n",
    "#測試集\n",
    "data_test = off_test\n",
    "feature3 = off_train[((off_train.date >= '20160315')&(off_train.date <= '20160630')) | ((off_train.date =='null') & (off_train.date >='20160315') & (off_train.date<='20160630'))]\n",
    "\n",
    "#訓練集二\n",
    "dataset2 = off_train[(off_train.date_received >= '20160515') & (off_train.date_received <= '20160615')]\n",
    "\n",
    "feature2 = off_train[((off_train.date >= '20160201')&(off_train.date <= '20160514')) | ((off_train.date =='null') & (off_train.date >='20160201') & (off_train.date<='20160514'))]\n",
    "\n",
    "#訓練集一\n",
    "dataset1 = off_train[(off_train.date_received >= '20160414') & (off_train.date_received <= '20160514')]\n",
    "\n",
    "feature1 = off_train[((off_train.date >= '20160101')&(off_train.date <= '20160413')) | ((off_train.date =='null') & (off_train.date >='20160101') & (off_train.date<='20160413'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def get_other_feature(dataset3,filename='other_feature3'):\n",
    "\n",
    "    #測試集提取用戶ID\n",
    "    t = data_test[['user_id']]\n",
    "    #相當於給原有數據加上一列，這個月用戶收取的所有優惠券數量，初始化為1\n",
    "    t['this_month_user_receive_all_coupon_count'] = 1\n",
    "    #將t按照用戶id 分組，然後統計所有用戶收取的優惠券數量，並初始化一個索引值\n",
    "    #groupby後先接上要合併的欄位，後面就是你想要做什麼事情，.agg可以用(sum、avg、count)等動作\n",
    "    t = t.groupby('user_id').agg('sum').reset_index()\n",
    "    #提取這個月用戶收到的相同的優惠券數量\n",
    "    t1 = data_test[['user_id','coupon_id']]\n",
    "    t1['this_month_user_receive_same_coupn_count'] = 1\n",
    "    #若groupby就是樞紐分析有兩欄位要使用中括號刮起來\n",
    "    t1 = t1.groupby(['user_id','coupon_id']).agg('sum').reset_index()\n",
    "\n",
    "    #提取測試數據的用戶id、coupon_id、優惠券接收的時間\n",
    "    t2 = data_test[['user_id','coupon_id','date_received']]\n",
    "\n",
    "    #將data_received 從object 轉 str \n",
    "    t2.date_received = t2.date_received.astype('str')\n",
    "    #如果出現相同的用戶接收相同的優惠券在接收時間上用':' 連接上第n次接受優惠券的時間\n",
    "    t2 = t2.groupby(['user_id','coupon_id'])['date_received'].agg(lambda x:':'.join(x)).reset_index()\n",
    "    #因為上一句所以可能有許多消費者使用，所以接下來要將牠們分開，將接收時間的一組按著':'分開，這樣就可以計算接受了央會勸的數量\n",
    "    t2['receive_number'] = t2.date_received.apply(lambda s:len(s.split(':')))\n",
    "    t2 = t2[t2.receive_number > 1]\n",
    "    #最大的接受日期\n",
    "    t2['max_date_received'] = t2.date_received.apply(lambda s:max([int (d) for d in s.split(\":\")]))\n",
    "    #最小的接受日期\n",
    "    t2['min_date_received'] = t2.date_received.apply(lambda s:min([int (d) for d in s.split(\":\")]))\n",
    "    #重新整理t2的數據\n",
    "    t2 = t2[['user_id','coupon_id','min_date_received','max_date_received']]\n",
    "\n",
    "    #將兩表融合只保留左表數據，這樣得到的表，相當於保留了最近接收時間和最遠接受時間\n",
    "    #意思為上面的操作已經拆分出每一個人領取每一種優惠券，最新與最舊的時間，然後再將這些表合併到最原始的表當中\n",
    "    t3 = data_test[['user_id','coupon_id','date_received']]\n",
    "    t3 = pd.merge(t3,t2,on=['user_id','coupon_id'],how='left')\n",
    "\n",
    "    #用戶領取特定優惠券的時間，是不是最後一次＆第一次\n",
    "    t3['this_month_user_receive_same_coupon_lastone'] =t3.max_date_received-t3.date_received.astype(int)\n",
    "    t3['this_month_user_receive_same_coupon_firstone'] = t3.date_received.astype(int)-t3.min_date_received\n",
    "    def is_firstlastone(x):\n",
    "        if x==0:\n",
    "            return 1 \n",
    "        elif x>0:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1 #表明優惠券僅接受了一次\n",
    "    #將上述定義的函數用到剛剛創建的 事不是第一次與最後一次領取特定的特徵中\n",
    "    t3.this_month_user_receive_same_coupon_lastone = t3.this_month_user_receive_same_coupon_lastone.apply(is_firstlastone)\n",
    "    t3.this_month_user_receive_same_coupon_firstone = t3.this_month_user_receive_same_coupon_firstone.apply(is_firstlastone)\n",
    "\n",
    "    #第四個特徵，一個用戶所接收到的所有優惠券的數量\n",
    "    t4 = data_test[['user_id','date_received']]\n",
    "    t4['this_day_receive_all_coupon_count']=1\n",
    "    t4 = t4.groupby(['user_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "    #提取第五個特徵，一個用戶不同時間所接收到不同優惠券的數量\n",
    "    t5 = data_test[['user_id','coupon_id','date_received']]\n",
    "    t5['this_day_user_receive_same_coupon_count']=1\n",
    "    t5 =t5.groupby(['user_id','coupon_id','date_received']).agg('sum').reset_index()\n",
    "\n",
    "    #一個用戶不同優惠券的接受時間\n",
    "    t6 = data_test[['user_id','coupon_id','date_received']]\n",
    "    t6.date_received=t6.date_received.astype(str)\n",
    "    t6 = t6.groupby(['user_id','coupon_id']).agg(lambda x:':'.join(x)).reset_index()\n",
    "    #重新命名inplace代表深拷貝\n",
    "    #inplace = True 意思為直接替換掉原有的dataframe\n",
    "    t6.rename(columns={'date_received':'dates'},inplace= True)\n",
    "\n",
    "    def get_day_gap_before (x):\n",
    "        date_received,dates=x.split('-')\n",
    "        dates =dates.split(':')\n",
    "        gaps=[]\n",
    "        for d in dates:\n",
    "            ##三个部分分别代表年月日   #将时间差转化为天数\n",
    "            this_gap=(date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))-date(int(d[0:4]),int(d[4:6]),int(d[6:8]))).days\n",
    "            if this_gap >0 :\n",
    "                gaps.append(this_gap)\n",
    "        if len(gaps)==0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "\n",
    "\n",
    "\n",
    "    def get_day_gap_after (x):\n",
    "        date_received,dates=x.split('-')\n",
    "        dates =dates.split(':')\n",
    "        gaps=[]\n",
    "        for d in dates:\n",
    "            this_gap=(date(int(d[0:4]),int(d[4:6]),int(d[6:8]))-date(int(date_received[0:4]),int(date_received[4:6]),int(date_received[6:8]))).days\n",
    "            if this_gap >0 :\n",
    "                gaps.append(this_gap)\n",
    "        if len(gaps)==0:\n",
    "            return -1\n",
    "        else:\n",
    "            return min(gaps)\n",
    "\n",
    "\n",
    "\n",
    "    t7 = data_test[['user_id','coupon_id','date_received']]\n",
    "    t7 = pd.merge(t7,t6,on=['user_id','coupon_id'],how='left')\n",
    "    t7['date_received_date'] = t7.date_received.astype('str')+'-'+t7.dates\n",
    "    t7['day_gap_before'] = t7.date_received_date.apply(get_day_gap_before)\n",
    "    t7['day_gap_after'] = t7.date_received_date.apply(get_day_gap_after)\n",
    "    t7 = t7[['user_id','coupon_id','date_received','day_gap_before','day_gap_after']]\n",
    "    #將所有特徵融合在一張表中\n",
    "    #上述提取的特征进行合并\n",
    "    other_feature3=pd.merge(t1,t,on='user_id')\n",
    "    other_feature3=pd.merge(other_feature3,t3,on=['user_id','coupon_id'])\n",
    "    other_feature3=pd.merge(other_feature3,t4,on=['user_id','date_received'])\n",
    "    other_feature3=pd.merge(other_feature3,t5,on=['user_id','coupon_id','date_received'])\n",
    "    other_feature3=pd.merge(other_feature3,t7,on=['user_id','coupon_id','date_received'])\n",
    "    other_feature3.to_csv(filename+'.csv',index=None)\n",
    "    return other_feature3\n",
    "\n",
    "other_feature3=get_other_feature(data_test,filename='other_feature3')\n",
    "other_feature2=get_other_feature(dataset2,filename='other_feature2')\n",
    "other_feature1=get_other_feature(dataset1,filename='other_feature1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def get_coupon_related_feature (dataset3,filename='coupon3_feature'):\n",
    "    #計算折扣率函數\n",
    "    def calc_discount_rate(s):\n",
    "        s = str(s)\n",
    "        s = s.split(':')\n",
    "        if len(s)==1:\n",
    "            return float(s[0])\n",
    "        else:\n",
    "            return 1.0-float(s[1])/float(s[0])\n",
    "    #提取滿多少送多少優惠券中，滿多少對應的金額\n",
    "    def get_discount_man(s):\n",
    "        s = str(s)\n",
    "        s = s.split(':')\n",
    "        if len(s) ==1:\n",
    "            return 'null'\n",
    "        else:\n",
    "            return int(s[0])\n",
    "    #提取滿XX優惠券中，送的金額\n",
    "    def get_discount_jian(s):\n",
    "        s = str(s)\n",
    "        s = s.split(':')\n",
    "        if len(s) ==1:\n",
    "            return 'null'\n",
    "        else:\n",
    "            return int(s[1])\n",
    "    #是不是滿優惠券\n",
    "    def is_man_jian(s):\n",
    "        s = str(s)\n",
    "        s=s.split(':')\n",
    "        if len(s)==1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1.0\n",
    "        \n",
    "    #周幾領取優惠券\n",
    "    dataset3['day_of_week'] = dataset3.date_received.astype('str').apply(lambda x:date(int(x[0:4]),int(x[4:6]),int(x[6:8])).weekday()+1)\n",
    "    \n",
    "    #每月第幾天領取優惠券\n",
    "    dataset3['day_of_month'] = dataset3.date_received.astype('str').apply(lambda x:int(x[6:8]))\n",
    "    \n",
    "    #領取優惠券的時間與截止日期差多少天\n",
    "    dataset3['days_distance'] = dataset3.date_received.astype('str').apply(lambda x:(date(int(x[0:4]),int(x[4:6]),int(x[6:8]))-date(2016,6,30)).days)\n",
    "    \n",
    "    #滿額優惠券中，滿額對應金額\n",
    "    dataset3['discount_man'] = dataset3.discount_rate.apply(get_discount_man)\n",
    "    \n",
    "    #滿額優惠券中，滿額對應的折扣數量\n",
    "    dataset3['discount_jian'] = dataset3.discount_rate.apply(get_discount_jian)\n",
    "    \n",
    "    #滿額優惠券中是不是滿額勸\n",
    "    dataset3['is_man_jian'] = dataset3.discount_rate.apply(is_man_jian)\n",
    "    \n",
    "    #優惠券折扣率(滿額勸進行折扣率轉換)\n",
    "    dataset3['discount_rate']=dataset3.discount_rate.apply(calc_discount_rate)\n",
    "    \n",
    "    #特定優惠券數量\n",
    "    d=dataset3[['coupon_id']]\n",
    "    d['coupon_count'] = 1\n",
    "    d=d.groupby('coupon_id').agg('sum').reset_index()\n",
    "    dataset3 = pd.merge(dataset3,d,how='left',on='coupon_id')\n",
    "    dataset3.to_csv(filename+'.csv',index=None)\n",
    "    \n",
    "    return dataset3\n",
    "coupon3_feautre=get_coupon_related_feature(data_test,filename='coupon3_feature')\n",
    "coupon2_feature=get_coupon_related_feature(dataset2,filename='coupon2_feature')\n",
    "coupon1_feature=get_coupon_related_feature(dataset1,filename='coupon1_feature')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#提取店家特徵\n",
    "def get_merchant_related_feature(feature3,filename='merchant3_feature'):\n",
    "    #對於測試集\n",
    "    merchant3 = feature3[['merchant_id','coupon_id','distance','date_received','date']]\n",
    "\n",
    "    #提取不重複的商品集和\n",
    "    m = merchant3[['merchant_id']]\n",
    "    m.drop_duplicates(inplace=True)\n",
    "\n",
    "    #用戶商品銷售次數\n",
    "    #從數據查看當date不等於null的意思，代表消費者消費了每個店家的商品但是他並沒有使用coupon券\n",
    "    m1=merchant3[merchant3.date!= 'null'][['merchant_id']]\n",
    "    m1['total_sales']=1\n",
    "    m1=m1.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "    #用戶被核銷消費券的銷售次數\n",
    "    #顯示使用優惠券消費的商品\n",
    "    #如數據提供的時候說，若優惠券使用的時候date 不等於 null 與 coupon_id 也不等於 null 所以這鞭先篩選此項\n",
    "    m2=merchant3[(merchant3.date !='null')&(merchant3.coupon_id!='null')][['merchant_id']]\n",
    "    m2['sales_use_coupon'] = 1\n",
    "        #顯示每個商品的總銷售數量\n",
    "    m2=m2.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "    #店家被核銷優惠券的銷售次數\n",
    "    #顯示了商品的優惠券的總數量\n",
    "    #意思是店家發出去商品的優惠券的總數，不管有沒有使用，所以只要coupon不等於null都是店家有發出去呃優惠券\n",
    "    m3=merchant3[merchant3.coupon_id!='null'][['merchant_id']]\n",
    "    m3['total_coupon']=1\n",
    "    m3=m3.groupby('merchant_id').agg('sum').reset_index()\n",
    "\n",
    "    #店家被核銷優惠券的用戶-店家距離，轉換數值(int)類型\n",
    "    #意思是顯示 商品銷量和距離的關係\n",
    "    #replace 意思為將某個數值取代為每個東西，例如這邊將null 取代成 -1 \n",
    "    #一般來說使用replace重新讀取原始資料不會變動，但inplace=True代表原始表格也將會被取代\n",
    "    m4 = merchant3[(merchant3.date != 'null') & (merchant3.coupon_id!='null')][['merchant_id','distance']]\n",
    "    #把數據中的null全部替換成-1\n",
    "    m4.replace('null',-1,inplace=True)\n",
    "    m4.distance=m4.distance.astype('int')\n",
    "    #再把-1替換成nan\n",
    "    m4.replace(-1,np.nan,inplace=True)\n",
    "\n",
    "    #用戶被使用優惠券的最小用戶-商店距離\n",
    "    #返回用戶離商品的距離最小值\n",
    "    m5 =m4.groupby('merchant_id').agg('min').reset_index()\n",
    "    m5.rename(columns={'distance':'merchant_min_distance'},inplace=True)\n",
    "\n",
    "    #返回用戶離商品的距離最大值\n",
    "    m6 =m4.groupby('merchant_id').agg('max').reset_index()\n",
    "    m6.rename(columns={'distance':'merchant_max_distance'},inplace=True)\n",
    "\n",
    "    #返回用戶離商品的距離平均值\n",
    "    m7 = m4.groupby('merchant_id').agg('mean').reset_index()\n",
    "    m7.rename(columns={'distance':'merchant_mean_distance'},inplace=True)\n",
    "\n",
    "    #返回用戶離商品的距離平均值\n",
    "    m8 = m4.groupby('merchant_id').agg('median').reset_index()\n",
    "    m8.rename(columns={'distance':'merchant_median_distance'},inplace=True)\n",
    "\n",
    "    #將各個特徵合併\n",
    "    merchant3_feature = pd.merge(m,m1,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,m2,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,m3,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,m5,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,m6,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,m7,on='merchant_id',how='left')\n",
    "    merchant3_feature = pd.merge(merchant3_feature,m8,on='merchant_id',how='left')\n",
    "    \n",
    "    #店家被核銷優惠券的銷售數量，若為空，填充為0\n",
    "    merchant3_feature.sales_use_coupon=merchant3_feature.sales_use_coupon.replace(np.nan,0)    \n",
    "\n",
    "    #店家發行優惠券的轉換率\n",
    "    merchant3_feature['merchant_coupon_conversion_rate'] =merchant3_feature.sales_use_coupon.astype('float')/merchant3_feature.total_coupon\n",
    "\n",
    "    #店家被核銷優惠券的銷售次數占比\n",
    "    merchant3_feature['coupon_rate'] = merchant3_feature.sales_use_coupon.astype('float') / merchant3_feature.total_sales\n",
    "    merchant3_feature.total_coupon=merchant3_feature.total_coupon.replace(np.nan,0)\n",
    "\n",
    "    merchant3_feature.to_csv(filename+'.csv',index=None)\n",
    "    return merchant3_feature\n",
    "\n",
    "merchant3_feature=get_merchant_related_feature(feature3,filename='merchant3_feature')\n",
    "merchant2_feature=get_merchant_related_feature(feature2,filename='merchant2_feature')\n",
    "merchant1_feature=get_merchant_related_feature(feature1,filename='merchant1_feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#使用者相關特徵\n",
    "def get_user_related_feature(feature3,filename='user_feature3'):\n",
    "    \n",
    "    #用戶領取優惠券與核銷的時間\n",
    "    def get_user_date_datereveived_gap(s):\n",
    "        s=s.split(':')\n",
    "        return (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8]))-\n",
    "                   date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days\n",
    "\n",
    "    user3=feature3[['user_id','merchant_id','coupon_id','discount_rate','distance','date_received','date']]\n",
    "\n",
    "    #提取不重複的所有用戶集合\n",
    "    u=user3[['user_id']]\n",
    "    u.drop_duplicates(inplace=True)\n",
    "\n",
    "    #用戶在特定店家消費次數\n",
    "    u1=user3[user3.date!='null'][['user_id','merchant_id']]\n",
    "     #因為可能一個人會重複買同一間店家的優惠券所以需要去重複\n",
    "    u1.drop_duplicates(inplace=True)\n",
    "    u1.merchant_id=1\n",
    "    u1=u1.groupby('user_id').agg('sum').reset_index()\n",
    "    u1.rename(columns={'merchant_id':'count_merchant'},inplace=True)\n",
    "\n",
    "    #提取用戶核銷優惠券的用戶-店家距離\n",
    "    u2=user3[(user3.date != 'null')&(user3.coupon_id != 'null')][['user_id','distance']]\n",
    "    #為何要先替換原因是，目前distance 為object類型，但object在pandas下使用偵測Null指令時時候偵測不到有null\n",
    "    #而且當數據裡面有null值的時候是無法將object 轉變為int\n",
    "    #所以先將所有Null值替換成-1，即可讓distance 轉變函數為int，函數再將原本的-1轉換為nan即可\n",
    "    u2.replace('null',-1,inplace=True)\n",
    "    u2.distance=u2.distance.astype('int')\n",
    "    u2.replace(-1,np.nan,inplace=True)\n",
    "\n",
    "    #得到使用優惠券購買商品的用戶離店家最短的距離\n",
    "    u3=u2.groupby('user_id').agg('min').reset_index()\n",
    "    u3.rename(columns={'distance':'user_min_distance'},inplace=True)\n",
    "\n",
    "    #得到使用優惠券購買商品的用戶離店家最遠的距離\n",
    "    u4=u2.groupby('user_id').agg('max').reset_index()\n",
    "    u4.rename(columns={'distance':'user_max_distance'},inplace=True)\n",
    "\n",
    "    #得到使用優惠券購買商品的用戶離店家平均的距離\n",
    "    u5=u2.groupby('user_id').agg('mean').reset_index()\n",
    "    u5.rename(columns={'distance':'user_mean_distance'},inplace=True)\n",
    "\n",
    "    #得到使用優惠券購買商品的用戶離店家中間的距離\n",
    "    u6=u2.groupby('user_id').agg('median').reset_index()\n",
    "    u6.rename(columns={'distance':'user_median_distance'},inplace=True)\n",
    "\n",
    "    #每個用戶使用優惠券購買的物品數量\n",
    "    u7=user3[(user3.date!='null')&(user3.coupon_id!='null')][['user_id']]\n",
    "    u7['buy_use_coupon']=1\n",
    "    u7=u7.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "    #購買物品的總數\n",
    "    u8=user3[(user3.date!='null')][['user_id']]\n",
    "    u8['buy_total']=1\n",
    "    u8=u8.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "    #接受優惠券的總數\n",
    "    u9=user3[(user3.coupon_id != 'null')][['user_id']]\n",
    "    u9['coupon_received']=1\n",
    "    u9=u9.groupby('user_id').agg('sum').reset_index()\n",
    "\n",
    "    #接受優惠券到使用優惠券的時間\n",
    "    u10=user3[(user3.date_received!='null')&(user3.date!='null')][['user_id','date_received','date']]\n",
    "    u10['user_date_datereceived_gap']=u10.date+':'+u10.date_received\n",
    "    u10.user_date_datereceived_gap = u10.user_date_datereceived_gap.apply(get_user_date_datereveived_gap)\n",
    "    u10 = u10[['user_id','user_date_datereceived_gap']]\n",
    "\n",
    "\n",
    "\n",
    "    #用戶核銷優惠券與領取優惠券的日期間隔平均值\n",
    "    u11=u10.groupby('user_id').agg('mean').reset_index()\n",
    "    u11.rename(columns={'user_date_datereceived_gap':'avg_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "    #用戶核銷優惠券與領取優惠券的日期間隔最小值\n",
    "    u12=u10.groupby('user_id').agg('min').reset_index()\n",
    "    u12.rename(columns={'user_date_datereceived_gap':'min_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "    #用戶核銷優惠券與領取優惠券的日期間隔最大值\n",
    "    u13=u10.groupby('user_id').agg('max').reset_index()\n",
    "    u13.rename(columns={'user_date_datereceived_gap':'max_user_date_datereceived_gap'},inplace=True)\n",
    "\n",
    "\n",
    "    #合併上述特徵\n",
    "    user3_feature=pd.merge(u,u1,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u3,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u4,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u5,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u6,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u7,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u8,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u9,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u10,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u11,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u12,on='user_id',how='left')\n",
    "    user3_feature=pd.merge(user3_feature,u13,on='user_id',how='left')\n",
    "    \n",
    "    #後續檢查中觀察到在合併之後有許多NAN的值所以需要缺失值的填充\n",
    "    user3_feature.count_merchant=user3_feature.count_merchant.replace(np.nan,0)\n",
    "    user3_feature.buy_use_coupon=user3_feature.buy_use_coupon.replace(np.nan,0)\n",
    "    \n",
    "    #用戶核銷優惠券消費次數占用戶總消費次數的比例\n",
    "    user3_feature['buy_use_coupon_rate']=user3_feature.buy_use_coupon.astype('float')/user3_feature.buy_total.astype('float')\n",
    "    \n",
    "    #用戶核銷優惠券消費次數佔用戶領取優惠次數的比例\n",
    "    user3_feature['user_coupon_transfer_rate']=user3_feature.buy_use_coupon.astype('float')/user3_feature.coupon_received.astype('float')\n",
    "    \n",
    "    \n",
    "    #\n",
    "    user3_feature.buy_total = user3_feature.buy_total.replace(np.nan,0)\n",
    "    user3_feature.coupon_received=user3_feature.coupon_received.replace(np.nan,0)\n",
    "\n",
    "    user3_feature.to_csv(filename+'.csv',index=None)\n",
    "    return user3_feature\n",
    "\n",
    "#對各數據集進行user_related_feature提取\n",
    "user3_feature=get_user_related_feature(feature3,filename='user_feature3')\n",
    "user2_feature=get_user_related_feature(feature2,filename='user_feature2')\n",
    "user1_feature=get_user_related_feature(feature1,filename='user_feature1')\n",
    "    \n",
    "                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                                0\n",
       "count_merchant                         0\n",
       "user_min_distance                 151914\n",
       "user_max_distance                 151914\n",
       "user_mean_distance                151914\n",
       "user_median_distance              151914\n",
       "buy_use_coupon                         0\n",
       "buy_total                              0\n",
       "coupon_received                        0\n",
       "user_date_datereceived_gap        145885\n",
       "avg_user_date_datereceived_gap    145885\n",
       "min_user_date_datereceived_gap    145885\n",
       "max_user_date_datereceived_gap    145885\n",
       "buy_use_coupon_rate                    0\n",
       "user_coupon_transfer_rate         145885\n",
       "dtype: int64"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user3_feature.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\austin\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#消費者與店家的交叉特徵\n",
    "def get_user_merchant_related_feature(feature3,filename='user_mechant3'):\n",
    "    \n",
    "    \n",
    "    #提取消費者與商家的交叉特徵\n",
    "    all_user_merchant=feature3[['user_id','merchant_id']]\n",
    "    all_user_merchant.drop_duplicates(inplace=True)\n",
    "    \n",
    "    #消費者在特定店家下的消費次數\n",
    "    a1=feature3[['user_id','merchant_id','date']]\n",
    "    a1=a1[a1.date != 'null'][['user_id','merchant_id']]\n",
    "    #消費者一共購買了這家店家的多少商品\n",
    "    a1['user_merchant_buy_total']=1\n",
    "    a1=a1.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    a1.drop_duplicates(inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #消費者在特定店家領取優惠券的次數\n",
    "    #記住若group by 兩個的話要+上 \"\" [ ] \"\"\n",
    "    a2=feature3[['user_id','merchant_id','coupon_id']]\n",
    "    a2=a2[a2.coupon_id!='null'][['user_id','merchant_id']]\n",
    "    #消費者一共收到的某間店家的多少優惠券\n",
    "    a2['user_merchant_received']=1\n",
    "    a2=a2.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    a2.drop_duplicates(inplace=True)\n",
    "    \n",
    "\n",
    "    \n",
    "    #消費者在特定店家使用優惠券的數量\n",
    "    a3=feature3[['user_id','merchant_id','date_received','date']]\n",
    "    a3=a3[(a3.date_received!='null')&(a3.date!='null')][['user_id','merchant_id']]\n",
    "    a3['user_merchant_buy_use_coupon']=1\n",
    "    a3=a3.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    a3.drop_duplicates(inplace=True)\n",
    "    \n",
    "    #消費者在特定店家發生行為的總次數\n",
    "    a4=feature3[['user_id','merchant_id']]\n",
    "    a4['user_merchant_any']=1\n",
    "    a4=a4.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    a4.drop_duplicates(inplace=True)\n",
    "    \n",
    "    #消費者在特定店家未領取優惠券產生的消費次數\n",
    "    a5=feature3[['user_id','coupon_id','merchant_id','date']]\n",
    "    a5=a5[(a5.date != 'null') & (a5.coupon_id =='null')][['user_id','merchant_id']]\n",
    "    a5['user_merchant_buy_common']=1\n",
    "    a5=a5.groupby(['user_id','merchant_id']).agg('sum').reset_index()\n",
    "    a5.drop_duplicates(inplace=True)\n",
    "    \n",
    "    #合併上述的資料\n",
    "    user_merchant3=pd.merge(all_user_merchant,a1,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant3=pd.merge(user_merchant3,a2,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant3=pd.merge(user_merchant3,a3,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant3=pd.merge(user_merchant3,a4,on=['user_id','merchant_id'],how='left')\n",
    "    user_merchant3=pd.merge(user_merchant3,a5,on=['user_id','merchant_id'],how='left')\n",
    "    \n",
    "    #缺失值填充\n",
    "    user_merchant3.user_merchant_buy_use_coupon= user_merchant3.user_merchant_buy_use_coupon.replace(np.nan,0)\n",
    "    user_merchant3.user_merchant_buy_use_coupon= user_merchant3.user_merchant_buy_use_coupon.replace(np.nan,0)    \n",
    "    \n",
    "    #消費者在特定店家處核銷優惠券佔領取優惠券的比例\n",
    "    user_merchant3['user_merchant_coupon_transfer_rate']=user_merchant3.user_merchant_buy_use_coupon.astype('float')/user_merchant3.user_merchant_received.astype('float')\n",
    "    \n",
    "    #消費者在特定店家使用優惠券佔購買次數的比例\n",
    "    user_merchant3['user_merchant_coupon_buy_rate']=user_merchant3.user_merchant_buy_use_coupon.astype('float')/user_merchant3.user_merchant_buy_total.astype('float')\n",
    "    \n",
    "    #消費者在特定店家購買次數佔購買次數的比例\n",
    "    user_merchant3['user_merchant_rate']=user_merchant3.user_merchant_buy_total.astype('float')/user_merchant3.user_merchant_any.astype('float')\n",
    "    \n",
    "    #消費者在特定店家下未使用優惠券購買佔購買次數的佔比\n",
    "    user_merchant3['user_merchant_common_buy_rate']=user_merchant3.user_merchant_buy_common.astype('float')/user_merchant3.user_merchant_buy_total.astype('float')\n",
    "    \n",
    "    user_merchant3.to_csv(filename+'.csv',index=None)\n",
    "    return user_merchant3\n",
    "\n",
    "user_merchant3=get_user_merchant_related_feature(feature3,filename='user_merchant3')\n",
    "user_merchant2=get_user_merchant_related_feature(feature2,filename='user_merchant2')\n",
    "user_merchant1=get_user_merchant_related_feature(feature1,filename='user_merchant1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練數據及測試數據集的建構\n",
    "def get_label(s):\n",
    "    s=s.split(':')\n",
    "    if s[0]=='nan':\n",
    "        return 0\n",
    "    elif (date(int(s[0][0:4]),int(s[0][4:6]),int(s[0][6:8]))-date(int(s[1][0:4]),int(s[1][4:6]),int(s[1][6:8]))).days<=15:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset3\n",
    "\n",
    "#提取相關的特徵\n",
    "coupon3=pd.read_csv('coupon3_feature.csv')\n",
    "merchant3=pd.read_csv('merchant3_feature.csv')\n",
    "user3=pd.read_csv('user_feature3.csv')\n",
    "user_merchant3=pd.read_csv('user_merchant3.csv')\n",
    "other_feature3=pd.read_csv('other_feature3.csv')\n",
    "\n",
    "#合併相關特徵\n",
    "dataset3=pd.merge(coupon3,merchant3,on='merchant_id',how='left')\n",
    "dataset3=pd.merge(dataset3,user3,on='user_id',how='left')\n",
    "dataset3=pd.merge(dataset3,user_merchant3,on=['user_id','merchant_id'],how='left')\n",
    "dataset3=pd.merge(dataset3,other_feature3,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset3.drop_duplicates(inplace=True)\n",
    "\n",
    "#相關特徵缺失值填充\n",
    "dataset3.user_merchant_buy_total=dataset3.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset3.user_merchant_any=dataset3.user_merchant_any.replace(np.nan,0)\n",
    "dataset3.user_merchant_received=dataset3.user_merchant_received.replace(np.nan,0)\n",
    "\n",
    "#用戶領取優惠院日期是否在周末\n",
    "dataset3['is_weekend'] =dataset3.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "\n",
    "#對優惠券的日期進行one-hot編碼\n",
    "weekday_dummies=pd.get_dummies(dataset3.day_of_week)\n",
    "weekday_dummies.columns=['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset3=pd.concat([dataset3,weekday_dummies],axis=1)\n",
    "\n",
    "#刪除特徵，這裡coupon_count是後面根據模型進行特徵篩選一些不太相關或是容易過擬合的特徵\n",
    "dataset3.drop(['merchant_id','day_of_week','coupon_count'],axis=1,inplace=True)\n",
    "dataset3=dataset3.replace('null',np.nan)\n",
    "\n",
    "dataset3.to_csv('dataset3.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset2\n",
    "\n",
    "#提取相關的特徵\n",
    "coupon2=pd.read_csv('coupon2_feature.csv')\n",
    "merchant2=pd.read_csv('merchant2_feature.csv')\n",
    "user2=pd.read_csv('user_feature2.csv')\n",
    "user_merchant2=pd.read_csv('user_merchant2.csv')\n",
    "other_feature2=pd.read_csv('other_feature2.csv')\n",
    "\n",
    "#合併相關特徵\n",
    "dataset2=pd.merge(coupon2,merchant2,on='merchant_id',how='left')\n",
    "dataset2=pd.merge(dataset2,user2,on='user_id',how='left')\n",
    "dataset2=pd.merge(dataset2,user_merchant2,on=['user_id','merchant_id'],how='left')\n",
    "dataset2=pd.merge(dataset2,other_feature2,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset2.drop_duplicates(inplace=True)\n",
    "\n",
    "#相關特徵缺失值填充\n",
    "dataset2.user_merchant_buy_total=dataset2.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset2.user_merchant_any=dataset2.user_merchant_any.replace(np.nan,0)\n",
    "dataset2.user_merchant_received=dataset2.user_merchant_received.replace(np.nan,0)\n",
    "\n",
    "#用戶領取優惠院日期是否在周末\n",
    "dataset2['is_weekend'] =dataset2.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "\n",
    "#對優惠券的日期進行one-hot編碼\n",
    "weekday_dummies=pd.get_dummies(dataset2.day_of_week)\n",
    "weekday_dummies.columns=['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset2=pd.concat([dataset2,weekday_dummies],axis=1)\n",
    "\n",
    "dataset2['label']=dataset2.date.astype('str')+':'+dataset2.date.astype('str')\n",
    "dataset2.label=dataset2.label.apply(get_label)\n",
    "\n",
    "#刪除特徵，這裡coupon_count是後面根據模型進行特徵篩選一些不太相關或是容易過擬合的特徵\n",
    "dataset2.drop(['merchant_id','day_of_week','coupon_count','date','date_received','coupon_id'],axis=1,inplace=True)\n",
    "dataset2=dataset2.replace('null',np.nan)\n",
    "dataset2=dataset2.replace('nan',np.nan)\n",
    "\n",
    "dataset2.to_csv('dataset2.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset1\n",
    "\n",
    "#提取相關的特徵\n",
    "coupon1=pd.read_csv('coupon1_feature.csv')\n",
    "merchant1=pd.read_csv('merchant1_feature.csv')\n",
    "user1=pd.read_csv('user_feature1.csv')\n",
    "user_merchant1=pd.read_csv('user_merchant1.csv')\n",
    "other_feature1=pd.read_csv('other_feature1.csv')\n",
    "\n",
    "#合併相關特徵\n",
    "dataset1=pd.merge(coupon1,merchant1,on='merchant_id',how='left')\n",
    "dataset1=pd.merge(dataset1,user1,on='user_id',how='left')\n",
    "dataset1=pd.merge(dataset1,user_merchant1,on=['user_id','merchant_id'],how='left')\n",
    "dataset1=pd.merge(dataset1,other_feature1,on=['user_id','coupon_id','date_received'],how='left')\n",
    "dataset1.drop_duplicates(inplace=True)\n",
    "\n",
    "#相關特徵缺失值填充\n",
    "dataset1.user_merchant_buy_total=dataset1.user_merchant_buy_total.replace(np.nan,0)\n",
    "dataset1.user_merchant_any=dataset1.user_merchant_any.replace(np.nan,0)\n",
    "dataset1.user_merchant_received=dataset1.user_merchant_received.replace(np.nan,0)\n",
    "\n",
    "#用戶領取優惠院日期是否在周末\n",
    "dataset1['is_weekend'] =dataset1.day_of_week.apply(lambda x:1 if x in (6,7) else 0)\n",
    "\n",
    "#對優惠券的日期進行one-hot編碼\n",
    "weekday_dummies=pd.get_dummies(dataset1.day_of_week)\n",
    "weekday_dummies.columns=['weekday'+str(i+1) for i in range(weekday_dummies.shape[1])]\n",
    "dataset1=pd.concat([dataset1,weekday_dummies],axis=1)\n",
    "\n",
    "dataset1['label']=dataset1.date.astype('str')+':'+dataset1.date.astype('str')\n",
    "dataset1.label=dataset1.label.apply(get_label)\n",
    "\n",
    "#刪除特徵，這裡coupon_count是後面根據模型進行特徵篩選一些不太相關或是容易過擬合的特徵\n",
    "dataset1.drop(['merchant_id','day_of_week','coupon_count','date','date_received','coupon_id'],axis=1,inplace=True)\n",
    "dataset1=dataset1.replace('null',np.nan)\n",
    "dataset1=dataset1.replace('nan',np.nan)\n",
    "\n",
    "dataset1.to_csv('dataset1.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
